{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/guides/functional_api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow module has been imported as tfk.\n",
      "  - keras is available.\n",
      "  - layers is available.\n",
      "  - models is available.\n",
      "  - Sequential is available.\n",
      "numpy module has been imported as np.\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "import importlib\n",
    "\n",
    "modules_to_check = [\n",
    "    {\n",
    "        'name': 'tensorflow', \n",
    "        'alias': 'tfk', \n",
    "        'symbols': ['keras', 'layers', 'models', 'Sequential']\n",
    "    },\n",
    "    {\n",
    "        'name': 'numpy', \n",
    "        'alias': 'np', \n",
    "        'symbols': []\n",
    "    },\n",
    "    #{\n",
    "    #    'name': 'nonexistent_module', \n",
    "    #    'alias': 'nonexistent', \n",
    "    #    'symbols': ['baz']\n",
    "    #}\n",
    "]\n",
    "\n",
    "for module_info in modules_to_check:\n",
    "    module_name = module_info['name']\n",
    "    module_alias = module_info['alias']\n",
    "    symbols_to_check = module_info['symbols']\n",
    "\n",
    "    try:\n",
    "        module = importlib.import_module(module_name)\n",
    "        globals()[module_alias] = module  # Assign the module to the desired alias\n",
    "        print(f\"{module_name} module has been imported as {module_alias}.\")\n",
    "\n",
    "        try:\n",
    "            for symbol in symbols_to_check:\n",
    "                print(f\"  - {symbol} is available.\")\n",
    "        except:\n",
    "            print(\"No symbols to check in this module.\")\n",
    "\n",
    "    except ImportError:\n",
    "        print(f\"{module_name} module has not been imported.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the `try` block encompass the `for` loop is considered the correct approach in this case for a couple of reasons:\n",
    "\n",
    "1. Granularity of error handling: Placing the `try` block outside the `for` loop allows for better granularity in error handling. If an error occurs within the `for` loop, it can be caught and handled within the loop itself, without aborting the entire loop. This way, you can handle errors for each symbol individually, if needed. On the other hand, if the `try` block is inside the loop, a single error might terminate the entire loop prematurely, preventing further checks.\n",
    "\n",
    "2. Separation of concerns: Placing the `try` block outside the `for` loop separates the concerns of importing the module and checking symbols. The `try` block primarily focuses on the import operation, ensuring that the module is imported successfully and the alias is assigned. The `for` loop, in turn, focuses on checking the availability of symbols within the module. Separating these concerns improves code readability and maintainability.\n",
    "\n",
    "However, there can be situations where the opposite approach (placing the `for` loop inside the `try` block) might have advantages in specific scenarios. For example:\n",
    "\n",
    "1. Batch error handling: If you want to handle any errors that occur during the entire loop as a batch, placing the `for` loop inside the `try` block can be useful. This way, any exception raised within the loop can be caught and handled in a single place, providing a consolidated error handling mechanism.\n",
    "\n",
    "2. Early termination on error: If encountering an error in any iteration of the loop should immediately terminate the loop, placing the `for` loop inside the `try` block might be beneficial. This way, a single error can break out of the loop early, avoiding unnecessary iterations if further checks are not required.\n",
    "\n",
    "In summary, while placing the `try` block outside the `for` loop is the generally recommended approach, the decision ultimately depends on the specific requirements and desired behavior of your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Sequential'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Example usage\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m----> 3\u001b[0m     model \u001b[39m=\u001b[39m tfk\u001b[39m.\u001b[39;49mSequential()\n\u001b[0;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtensorflow.keras module is available for use.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNameError\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Sequential'"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "try:\n",
    "    model = tfk.Sequential()\n",
    "    print(\"tensorflow.keras module is available for use.\")\n",
    "except NameError:\n",
    "    print(\"tensorflow.keras module is not available.\")\n",
    "\n",
    "try:\n",
    "    arr = np.array([1, 2, 3])\n",
    "    print(\"numpy module is available for use.\")\n",
    "except NameError:\n",
    "    print(\"numpy module is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start by creating an input node:\n",
    "\n",
    "inputs = keras.Input(shape=(784,))\n",
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You create a new node in the graph of layers by calling a layer on this inputs object:\n",
    "dense = layers.Dense(64, activation=\"relu\")\n",
    "x = dense(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to add more layers to the graph of layers:\n",
    "x = layers.Dense(64, activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Inputs to a layer should be tensors. Got: <keras.layers.core.dense.Dense object at 0x000002C8B5BE12D0>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m outputs \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39;49mDense(\u001b[39m10\u001b[39;49m)(x)\n",
      "File \u001b[1;32mc:\\Users\\dacamargo\\.conda\\envs\\py31012\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\dacamargo\\.conda\\envs\\py31012\\lib\\site-packages\\keras\\engine\\input_spec.py:213\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m inputs:\n\u001b[0;32m    208\u001b[0m     \u001b[39m# Having a shape/dtype is the only commonality of the various\u001b[39;00m\n\u001b[0;32m    209\u001b[0m     \u001b[39m# tensor-like objects that may be passed. The most common kind of\u001b[39;00m\n\u001b[0;32m    210\u001b[0m     \u001b[39m# invalid type we are guarding for is a Layer instance (Functional API),\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[39m# which does not have a `shape` attribute.\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 213\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInputs to a layer should be tensors. Got: \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    215\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(inputs) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(input_spec):\n\u001b[0;32m    216\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    217\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLayer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m expects \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(input_spec)\u001b[39m}\u001b[39;00m\u001b[39m input(s),\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    218\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m but it received \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(inputs)\u001b[39m}\u001b[39;00m\u001b[39m input tensors. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInputs received: \u001b[39m\u001b[39m{\u001b[39;00minputs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    220\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Inputs to a layer should be tensors. Got: <keras.layers.core.dense.Dense object at 0x000002C8B5BE12D0>"
     ]
    }
   ],
   "source": [
    "outputs = layers.Dense(10)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"test_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39msummary()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"my_first_model.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n",
      "Epoch 1/2\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3539 - sparse_categorical_accuracy: 0.9016 - val_loss: 0.2044 - val_sparse_categorical_accuracy: 0.9424\n",
      "Epoch 2/2\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1833 - sparse_categorical_accuracy: 0.9464 - val_loss: 0.1548 - val_sparse_categorical_accuracy: 0.9556\n",
      "313/313 - 1s - loss: 0.1510 - sparse_categorical_accuracy: 0.9556 - 679ms/epoch - 2ms/step\n",
      "Test loss: 0.1510082483291626\n",
      "Test accuracy: 0.9556000232696533\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=2, validation_split=0.2)\n",
    "\n",
    "test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " img (InputLayer)            [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 16)        160       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 8, 8, 32)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 32)          9248      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 16)          4624      \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 16)               0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,672\n",
      "Trainable params: 18,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_input = keras.Input(shape=(28, 28, 1), name=\"img\")\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(encoder_input)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(x)\n",
    "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float32'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py31012",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
